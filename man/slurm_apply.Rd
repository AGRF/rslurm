% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/slurm_apply.R
\name{slurm_apply}
\alias{slurm_apply}
\title{Parallel execution of a function on the SLURM cluster}
\usage{
slurm_apply(f, params, jobname = NA, cpus_per_node = 8, nodes = 16,
  data_file = NULL, pkgs = rev(.packages()))
}
\arguments{
\item{f}{A function that accepts one or many single values as parameters and
returns a single value or a vector.}

\item{params}{A data frame of parameter values to apply \code{f} to. Each
column corresponds to a parameter of \code{f} (\emph{Note}: names must 
match) and each row corresponds to a separate function call.}

\item{cpus_per_node}{number of CPUs per node on the cluster; determines how
many processes are run in parallel per node.}

\item{nodes}{The (maximum) number of cluster nodes to spread the calculation
over. \code{slurm_apply} automatically divides \code{params} in chunks of
approximately equal size to send to each node. Less nodes are allocated if 
the parameter set is too small to use all CPUs in the requested nodes.}

\item{data_file}{The name of a R data file (created with 
\code{\link[base]{save}}) that will be loaded on each node prior to
calling \code{f}.}

\item{pkgs}{A character vector containing the names of packages that must
be loaded on each cluster node. By default, it includes all packages
loaded by the user when \code{slurm_apply} is called.}
}
\value{
A \code{slurm_job} object containing the \code{file_prefix} assigned
  to temporary files created by \code{slurm_apply}, a \code{job_id} assigned
  by the SLURM cluster and the number of \code{nodes} effectively used.
}
\description{
Use \code{slurm_apply} to calculate a function over multiple sets of 
parameters in parallel, using up to 16 nodes of the SLURM cluster.
}
\details{
This function creates temporary files for the parameters data ("slr####.RData"),
the R script sent to each node ("slr####.R") and the Bash script 
("slr####.sh") that launches the parallel computation. The set of input 
parameters is divided in chunks sent to each node, and \code{f} is evaluated
in parallel within each node using functions from the \code{parallel} R
package.

Any other R objects (besides \code{params}) that \code{f} needs to access
should be saved in a .RData file (using \code{\link[base]{save}}) and the
name of this file should be given as the optional \code{data_file} argument.

When processing the computation job, the SLURM cluster will output two types
of files: those containing the return values of the function for each subset
of parameters ("slr####_[node_id].RData") and those containing any console or
error output produced by R on each node ("slurm-[job_id]_[node_id].out").

After sending the job to the SLURM cluster, \code{slurm_apply} returns a
\code{slurm_job} object which can be used to cancel the job, get the job 
status or output, and delete the temporary files associated with it. See 
the description of the related functions for more details.
}
\examples{
\dontrun{
sjob <- slurm_apply(func, pars)
print_job_status(sjob) # Prints console/error output once job is completed.
func_result <- get_slurm_out(sjob, "table") # Loads output data into R.
cleanup_files(sjob)
}
}
\seealso{
\code{\link{slurm_call}} to evaluate a single function call.

\code{\link{cancel_slurm}}, \code{\link{cleanup_files}}, 
  \code{\link{get_slurm_out}} and \code{\link{print_job_status}} 
  which use the output of this function.
}

